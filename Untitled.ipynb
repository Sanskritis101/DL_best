{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89402e97-84be-40b2-b6f3-b22f338cc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2061c9-f06b-4404-a148-537b0cc7f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '11 Flowers/train'\n",
    "test_dir = '11 Flowers/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d98979-afb9-4800-a3d3-da21c2179872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define img_size batch_size\n",
    "img_size= (224,224)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d587cf37-d0b1-4b20-846d-ea240ee0ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define img data gen for train val test\n",
    "train_dgen= ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_dgen= ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e343509-2c76-4122-8ea7-083514a34696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2602 images belonging to 5 classes.\n",
      "Found 648 images belonging to 5 classes.\n",
      "Found 530 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train_data = train_dgen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_dgen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_data = train_dgen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=batch_size,\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle= False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320cb6bf-3e0d-4af5-80a8-a5342d7ae611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model and freeze\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965336e4-13e4-4b66-983d-18b696bad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(train_data.num_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354cc0dd-9e55-4618-946d-13c0bd08ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8478bd-09d5-4cc6-a016-f50a62a72095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.7080 - loss: 0.7722 - val_accuracy: 0.8256 - val_loss: 0.4790\n",
      "Epoch 2/2\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.9050 - loss: 0.2803 - val_accuracy: 0.8611 - val_loss: 0.3793\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767ae194-3389-488e-ad38-c7cbffc15681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('flowers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0894f740-5962-40e0-95e2-2c0c8a657e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 818ms/step - accuracy: 0.8760 - loss: 0.3451\n",
      "Test Loss: 0.31853529810905457\n",
      "Test Accuracy: 0.8886792659759521\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a741dbb-51ab-405c-8513-2184f41b28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_labels = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3d8ea-f882-4670-8fa9-043840242a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy and display classification report\n",
    "test_acc = accuracy_score(true_classes, predicted_classes)\n",
    "print(f\"Accuracy on test data: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc6760-a551-4355-a565-47ec31c5e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get class labels\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n",
    "# Select a batch of images from the test set\n",
    "images, true_labels = next(test_data)  # Get a batch of images and labels\n",
    "predicted_probs = model.predict(images)\n",
    "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Display a few images with predictions and actual labels\n",
    "num_images = 5  # Number of images to display\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')\n",
    "    true_label = class_names[true_labels[i]]\n",
    "    predicted_label = class_names[predicted_labels[i]]\n",
    "    plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=color)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
